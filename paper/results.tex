\section{Analyses \& Results}
\label{sec_analyses}

\subsection{Comparison of tagged and untagged time series}
Our principal research question is whether listening patterns in tagged content are consistent with the expectation that tags serve as memory cues. If this were to be the case, we would expect to see increased listening rates for musical artists once a tag is applied, under the assumption that a tag facilitates retrieval and increaes the chances of a user listening to a tagged artist. 

Unfortunately, several factors combine to make such an analysis more difficult.  First and foremost, the desired counterfactual of the untagged ``version'' of a particular tagged series does not, of course, exist. We thus must utilized untagged time series in a way that allows them to approximate what a true counterfactual might look like.  In searching for such samples, a second difficulty that arises is that listening rates for tagged time series are much greater than for untagged time series (the average number of listens across all time series is 16.9  when untagged and 98.9 when tagged). While suggestive of the importance of tagging, this unbalance also suggests that controls must be instilled in both sample selection and statistical analysis to account for previous listening behavior prior to tagging to understand how it changes behavior.  Finally, the actual point in time at which tags are expected to increase listening behavior for any given user is unknown, as it is theoretically possible that tagging may affect listening behavior as much three months after the tag has been placed as it does in the immediately following month.  Thus, we must formulate our analysis in such a fashion as to account for this possibility.  

To alleviate issues with the non-existance of a true counterfactual, we meticulously subselect from both the tagged and untagged series using the following formal proceedure. We first temporally align the tagged and untagged time series. Tagged time series are aligned so that they are centered on the month in which they were tagged.  While there is no analogue to this point in the untagged data, we can partially resolve the issue by noting that tagging is disproportionately likely (approximately 30\%, compared to 1.1\% if random) to occur in a user's \emph{peak}\footnote{The month in which they listen the most times} listening month for a given artist.  This provides a basis for aligning the tagged and untagged time series, by selecting only those tagged time series where the tag was applied in the month of peak listening, and then collecting a sample of untagged time series also aligned at the peak of listening. After aligning all tagged and untagged samples in this fashion, we further limited our analysis to a 13 month period extending from 6 months prior to the peak month to 6 months after the peak. This data allows us to consider a variety of ways in which listening prior to the tag may affect future behavior, as well as the case where future behavior is affected well after the tag has been applied. Finally, we further constrain our sampling to time series with:
\begin{itemize}
\item more than 25 total listens; 
\item a peak in listening at least 6 months from the edges of our data collection perod (i.e. ensuring that the period from 6 months before to 6 months after the peak does not extend beyond the limits of our data range); and
\item at least one listen 6 months prior to and after the peak (i.e. if the peak occurs in July 2008, there should be at least one listen in January 2007, and one listening in January 2009).
\end{itemize}

Constraining our time series in this manner, we are left with a total 206,140 tagged time series, and randomly sampled from the 4.1M matching untagged time series an equal amount meeting the same three criteria.  All results below have been verified with multiple random samplings of the untagged data.

In Figure~\ref{fig:taggedVsUntagged} we plot mean playcounts, with 95\% normal confidence intervals, for tagged and untagged time series for each month in our analysis window. All values are normalized by the peak, and thus values at the peak month for both the tagged and untagged lines are unity. We observe that there does exist an increase in the mean normalized listening rate in the months after the peak as opposed to those prior for both tagged and untagged time series. Additionally, and more importantly, we also see a small but reliable effect wherein tagged time series show proportionally higher mean normalized listening rates after the peak month (in which the the tag was applied) as compared to untagged time series. This is suggestive of an increase in listening as a result of tagging.

While Figure~\ref{fig:taggedVsUntagged} indicates a slight difference in the normalized means of the tagged and untagged data that supports our hypothesis, there are two important caveats to the data in the plot. First, because listenening distributions are heavily skewed for any given month, the mean is not necessarily indicative of the distribution.  Though qualitative plots will be similar, further statistical analysis should use either a transformed version of the listening counts or an appropriate count-based methodology. Second, while normalization controls to some extent for differences in listening counts, we would prefer a method to explicitly account for listening behavior prior to and including the peak month on future behavior.

To more robustly test our hypothesis, we thus utilize a generalized additive regression model relating post- and pre-peak listening behavior. As we are unsure at what point post-tagging the effect of a tag may be strongest, we consider as an outcome variable the logarithm of the sum of all listens in the six months after a tag has been applied\footnote{We note that qualitative results do hold in each individual month. Also of note is our choice of using the log of the dependent data rather than a count-based regression model. The model used here appeared to fit better than the count-based methods we attempted}. Our independent variables are an indicator of whether or not the time series has been tagged, as well as the logarithm of the sum of listens for the peak month and the six previous months.  Finally, because of the volume of data we are dealing with, it did not make sense to make the assumption of linear dependence of the dependent variable on the independent variables. We therefore opted for a Generalized Additive Model (GAM) \cite{}, for which we utilized the R package mgcv \cite{}.

  \begin{figure}
    \subfloat[Mean log-transformed and normalized playcount by month. \label{fig:taggedVsUntagged}]{%
      \includegraphics[width=0.5\textwidth]{taggedVUntagged}
    }
    \hfill
    \subfloat[Regression results, with 95\% confidence interval. \label{fig:regression}]{%
      \includegraphics[width=0.45\textwidth]{regression_img}
    }
    \caption{Comparison of tagged and untagged listening time series}
    \label{fig:regression}
  \end{figure}

The regression model, which explained approximately 30\% of the variance in the data (adj. R-sq.), indicated that smoothed parameters for all previous months had a signficant effect on post-peak listening behavior.  As we cannot show the form of this effect for all model variables, Figure~\ref{fig:regression} instead displays a similar model which considers only the effect of listening in the peak month on post-peak listening. As this plot suggests and the full model confirms, we can conclude that, controlling for all previous listening behavior, a tag increases the logarithm of post-peak listens by .147 [.144,.150], indicating that the effect of a tag is associated with around 1.15 more listens, on average, than if it were not to have been applied.   

\subsection{Tag analysis}
To examine if and how different tags are associated with increased future listening, we ran a similar regression analysis described above.  Two changes were made. First, due to the data-hungry nature of the GAM, we chose to only control for listening in the peak month. This decision limited the computational difficulties associated with estimating the model and did not appear to affect model fit much in subsamples of the data.  Second, instead of a single tagged indicator, we included binary (present / not present) regressors for all unique tags that had at least 5 occurrences in our subsample. Among the $\sim200,000$ annotations captured by our tagged time series, this amounted to $\sim1,200$ unique tags. Of these, 108 proved to be statistically significant at $p <.001$. While we only have sufficient evidence to make claims about these 108 tags, qualitative examination of which tags are relatively strong predictors in the model proves informative as well.

The most telling observation is that commonly-used genre tags (e.g. "pop", "jazz", and "hip-hop") -- which are the most common tags overall in our full dataset -- tend to be weak, negative predictors of future listening. In contrast, relatively strong predictors (both positive and negative) appear to be relatively obscure, possibly idiosyncratic tags ("arguman-loved tracks", "mymusic", "leapsandbounds cdcollection"). \todo[inline]{It seems like it would be nice to have a full listing of the tags and coefficients for people to look at, but of course listing it untenable...maybe we link to it in a footnote? Or not worthi it?} To examine this trend quantitatively, we plot in Figure~\ref{fig:coefVsPopularity} global tag popularity (i.e. the total number of uses of a tag in our full dataset, which consists of $\sim 50$ million annotations) as a function of different categories of tags as a result of the regression model.  The categories give a representation of the statistical significance and coefficent value of the different tags, and a bootstrapped 95\% confidence interval is provided that summarizes the global tag popularity for all tags that fit within the category. The result is a clear trend which suggests that the most popular tags are significant, weakly negative predictors of future listening, while both positive and negatively strong predictors tend to be relatively unpopular.

  \begin{figure}
	\centering
      \includegraphics[width=0.7\textwidth]{tagRegressionQualAnalysis}
    \caption{Tags' global popularity as a function of coefficient in our regression model.}
    \label{fig:coefVsPopularity}
  \end{figure}

These data suggest that, at least for the small number of tags about which we can make statistically meaningful claims, those that are globally popular and well-known have relatively little effect on future listening, and are generally associated with small decreases in post-taggging listening rates. The tags that seem to ``matter'' (i.e. those that are relatively strong predictors of whether or not a user will listen to an artist after tagging it) are generally much less popular.