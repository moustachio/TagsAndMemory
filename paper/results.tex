\section{Analyses \& Results}
\label{sec_analyses}

\subsection{Comparison of tagged and untagged time series}
Our principal research question is whether listening patterns for tagged content are consistent with the expectation that tags serve as memory cues. If this were to be the case, we would expect to see increased listening rates for musical artists once a tag is applied, under the assumption that a tag facilitates retrieval and increaes the chances of a user listening to a tagged artist. 

Unfortunately, several factors combine to make such an analysis difficult.  First and foremost, the desired counterfactual of the untagged ``version'' of a particular tagged series does not, of course, exist. We thus must utilize untagged time series in a way that allows them to approximate what a true counterfactual might look like.  In searching for such samples, a second difficulty that arises is that listening rates for tagged time series are much greater than for untagged time series (the average number of total listens across time series is 16.9  when untagged and 98.9 when tagged). While suggestive of the importance of tagging, this unbalance also suggests that controls must be instilled in both sample selection and statistical analysis to account for previous listening behavior prior to tagging. Finally, the actual point in time at which tags are expected to increase listening behavior for any given user is unknown, as it is theoretically possible that tagging may affect listening behavior as much three months after the tag has been placed as it does in the immediately following month.  Thus, we must formulate our analysis in such a fashion as to account for this possibility.  
%to understand how it changes behavior

%meticulously
To alleviate issues with the non-existence of a true counterfactual, we subselect from both the tagged and untagged series using the following formal procedure. We first temporally align the tagged and untagged time series. Tagged time series are aligned so that they are centered on the month in which they were tagged.  While there is no analogue to this point in the untagged data, we can partially resolve the issue by noting that tagging is disproportionately likely (approximately 30\%, compared to 1.1\% if the tagging month were random) to occur in a user's \emph{peak}\footnote{The month in which they listen the most times} listening month for a given artist. This provides a basis for aligning the tagged and untagged time series, by selecting only those tagged time series where the tag was applied in the month of peak listening, and then collecting a sample of untagged time series also aligned at the peak of listening. After aligning all tagged and untagged samples in this fashion, we further limited our analysis to a 13 month period extending from 6 months prior to the peak month to 6 months after the peak. This data allows us to consider a variety of ways in which listening prior to the tag may affect future behavior, as well as the case where future behavior is affected well after the tag has been applied. Finally, we further constrain our sampling to time series with:
\begin{itemize}
\item more than 25 total listens; 
\item a peak in listening at least 6 months from the edges of our data collection period (i.e. ensuring that the period from 6 months before to 6 months after the peak does not extend beyond the limits of our data range); and
\item at least one listen 6 months prior to and after the peak (i.e. if the peak occurs in July 2008, there should be at least one listen in January 2007, and one listening in January 2009).
\end{itemize}

Constraining our time series in this manner, we are left with a total 206,140 tagged time series, and randomly sampled from the 4.1M matching untagged time series an equal number meeting the same three criteria.  All results below have been verified with multiple random samplings of the untagged data.

In Figure~\ref{fig:taggedVsUntagged} we plot mean playcounts, with 95\% normal confidence intervals, for tagged and untagged time series for each month in our analysis window. All values are normalized by the peak, and thus values at the peak month for both the tagged and untagged lines are unity. We observe that there does exist an increase in the mean normalized listening rate in the months after the peak as opposed to those prior for both tagged and untagged time series. Additionally, and more importantly, we also see a small but reliable effect wherein tagged time series show proportionally higher mean normalized listening rates after the peak month (in which the the tag was applied) as compared to untagged time series. This is suggestive of an increase in listening as a result of tagging.

While Figure~\ref{fig:taggedVsUntagged} indicates a slight difference in the normalized means of the tagged and untagged data that supports our hypothesis, there are two important caveats to the data in the plot. First, because listening distributions are heavily skewed for any given month, the mean is not necessarily representative of the distribution. Though qualitative plots will be similar, further statistical analysis should use either a transformed version of the listening counts or an appropriate count-based methodology. Second, while normalization controls for differences in listening counts to some extent, we would prefer a method to explicitly account for listening behavior prior to and including the peak month on future behavior.

To more robustly test our hypothesis, we thus utilize a regression model relating post- and pre-peak listening behavior. As we are unsure at what point post-tagging the effect of a tag may be strongest, we consider as an outcome variable the logarithm of the sum of all listens in the six months after a tag has been applied.\footnote{Qualitative, our results hold in each individual month. Also of note is our choice of using the log of the dependent variable rather than a count-based regression model. The model used here appeared to fit better than the count-based methods we attempted.} Our independent variables are an indicator of whether or not the time series has been tagged, as well as the logarithm of the sum of listens for the peak month and the six previous months.  Finally, due to the volume of data we are dealing with, it was unreasonable make the assumption of linear dependence of the dependent variable on the independent variables. We therefore opted for a Generalized Additive Model (GAM, \cite{hastie1990generalized}), for which we utilized the R package mgcv \cite{wood2001mgcv}.

  \begin{figure}
    \subfloat[Mean normalized playcount by month. \label{fig:taggedVsUntagged}]{%
      \includegraphics[width=0.5\textwidth]{taggedVUntaggedSimple.png}
    }
    \hfill
    \subfloat[Regression results, with 95\% confidence interval. \label{fig:regression}]{%
      \includegraphics[width=0.45\textwidth]{taggedVUntaggedRegression.png}
    }
    \caption{Comparison of tagged and untagged listening time series}
    \label{fig:regressionFigs}
  \end{figure}

The regression model, which explained approximately 30\% of the variance in the data (adj. R-sq.), indicated that smoothed parameters for all previous months had a signficant effect on post-peak listening behavior.  As we cannot show the form of this effect for all model variables, Figure~\ref{fig:regression} instead displays a similar model which considers only the effect of listening in the peak month on post-peak listening. As this plot suggests and the full model confirms, we can conclude that, controlling for all previous listening behavior, a tag increases the logarithm of post-peak listens by .147 [.144,.150]. Thisindicates that the effect of a tag is associated with around 1.15 more listens, on average, than if it were not to have been applied.   

\subsection{Tag analysis}
To examine if and how different tags are associated with increased future listening, we ran a regression analysis similar to that described above, except for three changes. First, we eliminated the constraint that an annotation must occur in the pea month of a time series, as there is no meaninguful comparison to be made with untagged data in this analysis. Second, due to the data-hungry nature of the GAM, we chose to only control for listening in the peak month. This decision limited the computational difficulties associated with estimating the model and did not appear to affect model fit substantially in subsamples of the data. Third, instead of a single tagged/untagged indicator, we included binary (present / not present) regressors for all unique tags that had at least 25 occurrences in our subsample.  This expanded sample consisted of XXX,XXX tagged time series, with X,XXX unique tags. After running the model, which explains $\sim$XX\% of the variance in the data (adj. R-sq.), XXX unique tags  proved to be statistically significant predictors at $p <.001$. While we only have sufficient evidence to make claims about these XXX tags, qualitative examination of which tags are relatively strong predictors in the model proves informative.

The most telling observation is that commonly-used genre tags (e.g. ``pop'', ``jazz'', and ``hip-hop'') -- which are the most common tags overall in our full dataset -- tend to be weak, negative predictors of future listening. In contrast, relatively strong predictors (both positive and negative) appear to be comparatively obscure, possibly idiosyncratic tags (``arguman-loved tracks'', ``mymusic'', ``leapsandbounds cdcollection'').\footnote{For a full listing of the regression coefficients across all tags in the model, see \url{https://dl.dropboxusercontent.com/u/625604/papers/lorince.joseph.todd.2015.sbp.supplemental/regression_coefficients.txt}} To examine this trend quantitatively, we plot in Figure~\ref{fig:coefVsPopularity} global tag popularity (i.e. the total number of uses of a tag in our full dataset, which consists of $\sim 50$ million annotations) as a function of the tag's coefficient in the regression model. The red bands marked the upper and lower limits of a bootstrapped 95\% confidence interval on the popularity of the remaining XXX tags that were \emph{not} significant in the regression model. The result is a clear trend which suggests that the most popular tags are significant, weakly negative predictors of future listening, while both positive and negatively strong predictors tend to be relatively unpopular. Tags which were not significant in the model tend to be of moderate to high popularity

  \begin{figure}
	\centering
      \includegraphics[width=0.7\textwidth]{scatterplotTagRegression.png}
    \caption{Logarithm of tags' global popularity as a function of regression coefficient.}
    \label{fig:coefVsPopularity}
  \end{figure}

These data suggest that, at least for the small number of tags about which we can make statistically meaningful claims, those that are globally popular and well-known have relatively little effect on future listening, and are generally associated with small decreases in post-taggging listening rates. The tags that seem to ``matter'' (i.e. those that are relatively strong predictors of whether or not a user will listen to an artist after tagging it) are generally much less popular.